---
title: 为深度学习设计高效的数据加载器
date: 2017-09-28 09:27:27
tags:
    - mxnet
    - deeplearning
---

翻译自：https://mxnet.incubator.apache.org/architecture/note_data_loading.html

在任何机器学习系统中，数据加载都是很重要的一部分。当我们处理很小的数据集时，我们可以把整个数据集加载到 GPU 的内存中。对于大的数据集，我们必须把训练样本放在主内存。当数据集大到主内存都放不下时，数据加载就变成影响性能的很重要的一点。设计数据加载器时，我们的目标是高效的数据加载和数据准备，并且提供一个干净灵活的接口。

<!--more-->

这篇文章的结构如下：

  * **对 IO 设计的理解：** 数据加载的原则指南。
  * **数据格式：** 我们的解决方案是用 dmlc-core 库的二进制 recordIO 实现。
  * **数据加载：** 为减小 IO 开销，我们使用 dmlc-core 提供的基于线程的迭代器。
  * **接口设计：** 设计接口使用户可以用几行 Python 代码来写一个 MXNet 数据迭代器。
  * **扩展性：** 一些前瞻性的想法，使数据加载更加灵活。

我们的分析会提供一些对高效的 IO 系统的需求。

**关键需求列表**

  * 小的文件尺寸
  * 并行（分布式）的文件打包
  * 快速的文件加载和在线数据增强
  * 在分布式环境中从数据集的任意位置快速读取

## 对 IO 设计的理解

要设计一个 IO 系统，我们必须解决两个问题：数据准备和数据加载。数据准备通常是在线下做的，而数据加载是在线上做的，会影响线上的性能。在这一节中，我们将介绍关于这两个问题上对 IO 设计的理解。

### 数据准备

数据准备是指为后续处理将数据导报成所需要的格式的过程。当处理像 ImageNet 这样的大数据集时，这个过程可能很费时间。在这些情况下，有几种启发式的方法：

  * 将数据集打包成几个文件。一个数据集可能包含上百万的训练样本，打包过的数据可以方便地在机器之间传输。
  * 仅打包一次。我们不想对每个运行时环境重新进行打包，比如在机器的数量变化时。
  * 并行地进行打包。
  * 要可以方便地访问任意位置的数据。这对风不是机器学习的数据并行非常关键。当数据被打包成几个文件时，这会变得复杂。需要的行为可能是：打包后的数据可以被逻辑上分成任意数量的分区，不论打包成多少个物理上的文件。例如，如果我们把 1000 个图片打包成 4 个文件，每个文件包含 250 个图片。如果我们使用 10 台机器去训练 DNN，我们应该能够为每台机器加载大约 100 个图片。某些机器可能需要从不同的物理文件中加载图片。

### 数据加载

下一步需要考虑的是如何将数据加载到 RAM。我们的目标是尽可能快地加载数据。我们可以尝试遵守以下几个启发式的原则：

  * **使读操作连续：** 在磁盘上连续位置的读取速度更快。
  * **减少需要加载的字节数：** 我们可以压缩存储数据，例如，用 JPEG 格式保存图片。
  * **在不同的线程中加载和训练：** 这可以避免在加载数据时造成计算的瓶颈。
  * **节省 RAM：** 小心地决定是否将整个文件读入内存。

## 数据格式

因为深度神经网络的训练通常会用到大量数据，所以数据格式应该高效并且方便使用。要达到这个目标，我们需要用可以分割 (splittable) 的格式打包数据。在 MXNet 中，我们依赖于 dmlc-core 中实现的二进制 recordIO 格式。

### 二进制数据记录 (Binary Record)

![baserecordio.jpg](./baserecordio.jpg)

在 MXNet 的二进制 RecordIO 中，我们把每个数据实例存储为一个记录。**kMagic** 是个魔法数代表记录的起始位置。**Lrecord** 编码记录长度和一个标志。在 Irecord 中，

  * cflag == 0: 这是个完整的记录
  * cflag == 1: 多记录 (multi-record) 的开始
  * cflag == 2: 多记录的中间
  * cflag == 3: 多记录的结束

**Data** 是用来存储数据内容的空间。**Pad** 为了让记录按 4 字节对齐做的填充。
